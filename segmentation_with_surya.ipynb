{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surya.detection import batch_text_detection\n",
    "from surya.layout import batch_layout_detection\n",
    "from surya.model.detection.segformer import load_model, load_processor\n",
    "from surya.settings import settings\n",
    "from PIL import Image\n",
    "import os\n",
    "import io\n",
    "import fitz\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Layout Detection and Processing Tool\n",
    "\n",
    "A robust tool for processing PDFs to detect and extract text/layout elements using \n",
    "the Surya detection framework. The script handles multiple PDFs, extracting and analyzing\n",
    "each page while maintaining a structured output format.\n",
    "  \n",
    "The script expects PDFs in a `paper_example` directory and creates separate output \n",
    "directories for each processed PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models and processors for text detection and layout recognition\n",
    "det_processor = load_processor()\n",
    "det_model = load_model()\n",
    "rec_model = load_model(checkpoint=settings.LAYOUT_MODEL_CHECKPOINT)\n",
    "rec_processor = load_processor(checkpoint=settings.LAYOUT_MODEL_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_pages(pdf_path: str) -> List[Image.Image]:\n",
    "\n",
    "    \"\"\"\n",
    "    Convert PDF pages to PIL Images for processing.\n",
    "    Uses PyMuPDF to handle PDF conversion while maintaining image quality.\n",
    "    \"\"\"\n",
    "    \n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    images = []\n",
    "    for page in pdf_document:\n",
    "        # Convert page to pixmap for high-quality rendering\n",
    "        pix = page.get_pixmap()\n",
    "        # Convert to PNG format for consistent image processing\n",
    "        img = Image.open(io.BytesIO(pix.tobytes(output=\"png\")))\n",
    "        images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(images: List[Image.Image],\n",
    "                  det_model, det_processor,\n",
    "                  rec_model, rec_processor,\n",
    "                  output_dir: Path) -> None:\n",
    "    \n",
    "    \"\"\"\n",
    "    Two-stage pipeline for document analysis:\n",
    "    1. Text region detection using detection model\n",
    "    2. Layout analysis of detected regions\n",
    "    \n",
    "    Processes each image through both stages and saves results.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        try:\n",
    "            # Detect text regions in the image\n",
    "            line_predictions = batch_text_detection([image], det_model, det_processor)\n",
    "            \n",
    "            # Analyze layout structure of detected regions\n",
    "            layout_predictions = batch_layout_detection(\n",
    "                [image], rec_model, rec_processor, line_predictions\n",
    "            )\n",
    "            layout = layout_predictions[0]\n",
    "            \n",
    "            # Save detected regions if bounding boxes exist\n",
    "            if layout.bboxes:\n",
    "                save_images(image, i, layout.bboxes, output_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {i}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(image: Image.Image, page_num: int, boxes: List[any], output_dir: Path) -> None:\n",
    "\n",
    "    \"\"\"\n",
    "    Extract and save detected figures from document.\n",
    "    Creates separate PNG files for each detected figure region.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, box in enumerate(boxes):\n",
    "        if box.label == \"Figure\":\n",
    "            output_path = output_dir / f'image_page{page_num}_{i}.png'\n",
    "            bbox = box.bbox\n",
    "            # Crop and save the figure using bounding box coordinates\n",
    "            fig = image.crop((bbox[0], bbox[1], bbox[2], bbox[3]))\n",
    "            fig.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate input directory exists\n",
    "pdf_dir = Path(\"paper_example\")\n",
    "if not pdf_dir.exists():\n",
    "    raise FileNotFoundError(f\"PDF directory {pdf_dir} not found\")\n",
    "\n",
    "# Process all PDFs in the directory\n",
    "for pdf_file in pdf_dir.glob(\"*.pdf\"):\n",
    "    try:\n",
    "        # Create separate output directory for each PDF's extracted images\n",
    "        output_dir = pdf_file.with_suffix('') / \"cropped_images\"\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Process PDF pages and extract figures\n",
    "        images = load_pdf_pages(str(pdf_file))\n",
    "        process_images(images, det_model, det_processor,\n",
    "                      rec_model, rec_processor, output_dir)\n",
    "        print(f\"Processed {pdf_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_file}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image File Cleanup\n",
    "\n",
    "The following code removes images smaller than 4KB from specified directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_keep_image(image_path: Path, min_size_kb: int = 4) -> bool:\n",
    "   \n",
    "   \"\"\"Check if image is larger than minimum size in KB\"\"\"\n",
    "   \n",
    "   try:\n",
    "       size_kb = os.path.getsize(image_path) / 1024\n",
    "       return size_kb > min_size_kb\n",
    "   except Exception as e:\n",
    "       print(f\"Error checking size of {image_path}: {e}\")\n",
    "       return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_small_images(base_dir: Path):\n",
    "   \n",
    "   \"\"\"Remove images smaller than 3KB from all subdirectories\"\"\"\n",
    "   \n",
    "   for pdf_dir in base_dir.glob(\"*/cropped_images\"):\n",
    "       for image_path in pdf_dir.glob(\"*.png\"):\n",
    "           if not should_keep_image(image_path):\n",
    "               image_path.unlink()\n",
    "               print(f\"Removed {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"paper_example\")\n",
    "cleanup_small_images(base_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
