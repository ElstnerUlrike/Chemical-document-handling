{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key='YOUR_OPENAI_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Molecular Structure Extraction Models Using LLMs as a Judge \n",
    "\n",
    "This code compares SMILES strings extracted by different models against the ground truth from the IMAGE2SMILES dataset (as presented in 'Image2SMILES: Transformer-based Molecular Optical Recognition Engine'). The workflow involves:\n",
    "\n",
    "Merging the extracted SMILES with their corresponding ground truth values in a DataFrame\n",
    "Using GPT-4 to evaluate the accuracy of the extracted SMILES by comparing them to the ground truth\n",
    "Recording GPT-4's binary assessments ('YES'/'NO') in a separate column\n",
    "Calculating the frequency of correct and incorrect extractions based on these assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge two csv files by the image name\n",
    "def merge_csv_by_filename(file1, file2, output_file, suffix2='_model2'):\n",
    "    # load the csv files\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "\n",
    "    # delete the .png from the Image column\n",
    "    df2['Image'] = df2['Image'].str.replace('.png', '')\n",
    "\n",
    "    # add the ground truth to the dataframe\n",
    "    merged_df = pd.merge(df1, df2, on=\"Image\", suffixes=('_ground_trouth', suffix2))\n",
    "\n",
    "    # save the merged dataframe\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"Die Dateien wurden erfolgreich zusammengeführt und in '{output_file}' gespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_csv_by_filename('FG-SMILES-test-dataset.csv', 'smiles_results.csv', 'Metriken_gpt_4o_mini_smiles.csv', '_gpt_4o_mini')\n",
    "merge_csv_by_filename('FG-SMILES-test-dataset.csv', 'smiles_results_gpt_4o.csv', 'Metriken_gpt_4o.csv', '_gpt_4o')\n",
    "merge_csv_by_filename('FG-SMILES-test-dataset.csv', 'gemini_smiles_results.csv', 'Metriken_gemini_smiles.csv', '_gemini')\n",
    "merge_csv_by_filename('FG-SMILES-test-dataset.csv', 'gemini_smiles_experimental_results.csv', 'Metriken_gemini_experimental_1206_smiles.csv', '_gemini_experimental_1206')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv files\n",
    "df_gpt_4o_mini = pd.read_csv('Metriken_gpt_4o_mini_smiles.csv')\n",
    "\n",
    "# delete the columns DOI and Page\n",
    "df_gpt_4o_mini = df_gpt_4o_mini.drop(columns=['DOI', 'Page'])\n",
    "\n",
    "df_gpt_4o_mini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv files\n",
    "df_gpt_4o = pd.read_csv('Metriken_gpt_4o.csv')\n",
    "\n",
    "# delete the columns DOI and Page\n",
    "df_gpt_4o = df_gpt_4o.drop(columns=['DOI', 'Page'])\n",
    "\n",
    "df_gpt_4o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv files\n",
    "df_gemini = pd.read_csv('Metriken_gemini_smiles.csv')\n",
    "\n",
    "# delete the columns DOI and Page\n",
    "df_gemini = df_gemini.drop(columns=['DOI', 'Page'])\n",
    "\n",
    "df_gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini-experimental-1206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv files\n",
    "df_gemini_experimental_1206 = pd.read_csv('Metriken_gemini_experimental_1206_smiles.csv')\n",
    "\n",
    "# delete the columns DOI and Page\n",
    "df_gemini_experimental_1206 = df_gemini_experimental_1206.drop(columns=['DOI', 'Page'])\n",
    "\n",
    "df_gemini_experimental_1206"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4o as a Judge - Evaluation of the SMILES extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of the differences between SMILES and FG-SMILES for the LLM\n",
    "description = \"\"\"SMILES notation represents molecules, while Markush structures are molecular templates. \n",
    "There is no way of representing molecular templates in standard SMILES, so we designed a modified syntax. \n",
    "We named it FG-SMILES (functional groups smiles). This is an extension of standard SMILES, where a substituent or \n",
    "R-group can be written as a single pseudo-atom. If a substituent is a functional group, FG-SMILES can be translated \n",
    "to SMILES directly by replacing corresponding pseudo-atoms. An example:\n",
    "\n",
    "SMILES: Cc1cc(C)c(-c2ccccc2)c(-c2ccc([N+](=O)[O-])cc2)c1\n",
    "\n",
    "FG-SMILES: [Me]c1cc([Me])c(-[Ph])c(-c2ccc([NO2])cc2)c1\n",
    "\n",
    "FG-SMILES notation allows describing variable R-group position. We add the v symbol to denote the variable R-group \n",
    "inside an aromatic system. For example, the template c1[vR’]cccc([R2])c1 represents the template in (Figure 6). \n",
    "Formally, this notation breaks SMILES grammar because the branching atom is inside the ring, but it represents the \n",
    "case when R-group is attached not to a specific place in the ring but to the ring itself.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_gpt_4o_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the rows of the dataframe\n",
    "for row in df.itertuples(index=True, name=\"Pandas\"):\n",
    "    image = row.Image\n",
    "    smiles = row.SMILES_gpt_4o_mini\n",
    "    fg_smiles = row.SMILES_ground_trouth\n",
    "    print(f\"Index: {row.Image}, SMILES: {row.SMILES_gpt_4o_mini}, FG-SMILES: {row.SMILES_ground_trouth}\")\n",
    "    \n",
    "    # Prompt for the GPT-4 model\n",
    "    prompt = f\"\"\"\n",
    "    Compare the following SMILES and FG-SMILES. Determine whether the molecules they represent are structurally equivalent. \n",
    "    Respond only with \\\"Yes\\\" or \\\"No\\\".\n",
    "    \n",
    "    SMILES: {smiles}\n",
    "    FG-SMILES: {fg_smiles}\n",
    "    \"\"\"\n",
    "    \n",
    "    # send prompt to OpenAI\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    \n",
    "    # answer from OpenAI\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "    \n",
    "    # results dictionary\n",
    "    results[image] = answer\n",
    "\n",
    "# show results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_gpt_4o_mini = pd.DataFrame(results.items(), columns=[\"Image\", \"Result\"])\n",
    "\n",
    "# combine the results with the original dataframe\n",
    "df_gpt_4o_mini = pd.merge(df_gpt_4o_mini, df_results_gpt_4o_mini, on=\"Image\")\n",
    "df_gpt_4o_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a csv file\n",
    "df_gpt_4o_mini.to_csv(\"Metriken_gpt_4o_mini_smiles_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selt all rows where the result is not \"Yes\" and set the result to \"No\"\n",
    "df_gpt_4o_mini.loc[df_gpt_4o_mini[\"Result\"] != \"Yes\", \"Result\"] = \"No\"\n",
    "\n",
    "# count the results for Yes and No\n",
    "df_gpt_4o_mini[\"Result\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_gpt_4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the rows of the dataframe\n",
    "for row in df.itertuples(index=True, name=\"Pandas\"):\n",
    "    image = row.Image\n",
    "    smiles = row.SMILES_gpt_4o_mini\n",
    "    fg_smiles = row.SMILES_ground_trouth\n",
    "    print(f\"Index: {row.Image}, SMILES: {row.SMILES_gpt_4o_mini}, FG-SMILES: {row.SMILES_ground_trouth}\")\n",
    "    \n",
    "    # Prompt for the GPT-4 model\n",
    "    prompt = f\"\"\"\n",
    "    Compare the following SMILES and FG-SMILES. Determine whether the molecules they represent are structurally equivalent. \n",
    "    Respond only with \\\"Yes\\\" or \\\"No\\\".\n",
    "    \n",
    "    SMILES: {smiles}\n",
    "    FG-SMILES: {fg_smiles}\n",
    "    \"\"\"\n",
    "    \n",
    "    # send prompt to OpenAI\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    \n",
    "    # answer from OpenAI\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "    \n",
    "    # results dictionary\n",
    "    results[image] = answer\n",
    "\n",
    "# show results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_gpt_4o = pd.DataFrame(results.items(), columns=[\"Image\", \"Result\"])\n",
    "\n",
    "# combine the results with the original dataframe\n",
    "df_gpt_4o = pd.merge(df_gpt_4o, df_results_gpt_4o, on=\"Image\")\n",
    "df_gpt_4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a csv file\n",
    "df_gpt_4o.to_csv(\"Metriken_gpt_4o_smiles_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selt all rows where the result is not \"Yes\" and set the result to \"No\"\n",
    "df_gpt_4o.loc[df_gpt_4o[\"Result\"] != \"Yes\", \"Result\"] = \"No\"\n",
    "\n",
    "# count the results for Yes and No\n",
    "df_gpt_4o[\"Result\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the rows of the dataframe\n",
    "for row in df.itertuples(index=True, name=\"Pandas\"):\n",
    "    image = row.Image\n",
    "    smiles = row.SMILES_gpt_4o_mini\n",
    "    fg_smiles = row.SMILES_ground_trouth\n",
    "    print(f\"Index: {row.Image}, SMILES: {row.SMILES_gpt_4o_mini}, FG-SMILES: {row.SMILES_ground_trouth}\")\n",
    "    \n",
    "    # Prompt for the GPT-4 model\n",
    "    prompt = f\"\"\"\n",
    "    Compare the following SMILES and FG-SMILES. Determine whether the molecules they represent are structurally equivalent. \n",
    "    Respond only with \\\"Yes\\\" or \\\"No\\\".\n",
    "    \n",
    "    SMILES: {smiles}\n",
    "    FG-SMILES: {fg_smiles}\n",
    "    \"\"\"\n",
    "    \n",
    "    # send prompt to OpenAI\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    \n",
    "    # answer from OpenAI\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "    \n",
    "    # results dictionary\n",
    "    results[image] = answer\n",
    "\n",
    "# show results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_gemini = pd.DataFrame(results.items(), columns=[\"Image\", \"Result\"])\n",
    "\n",
    "# combine the results with the original dataframe\n",
    "df_gemini = pd.merge(df_gemini, df_results_gemini, on=\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a csv file\n",
    "df_gemini.to_csv(\"Metriken_gemini_smiles_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selt all rows where the result is not \"Yes\" and set the result to \"No\"\n",
    "df_gemini.loc[df_gpt_4o[\"Result\"] != \"Yes\", \"Result\"] = \"No\"\n",
    "\n",
    "# count the results for Yes and No\n",
    "df_gemini[\"Result\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini-experimental-1206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_gemini_experimental_1206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the rows of the dataframe\n",
    "for row in df.itertuples(index=True, name=\"Pandas\"):\n",
    "    image = row.Image\n",
    "    smiles = row.SMILES_gpt_4o_mini\n",
    "    fg_smiles = row.SMILES_ground_trouth\n",
    "    print(f\"Index: {row.Image}, SMILES: {row.SMILES_gpt_4o_mini}, FG-SMILES: {row.SMILES_ground_trouth}\")\n",
    "    \n",
    "    # Prompt for the GPT-4 model\n",
    "    prompt = f\"\"\"\n",
    "    Compare the following SMILES and FG-SMILES. Determine whether the molecules they represent are structurally equivalent. \n",
    "    Respond only with \\\"Yes\\\" or \\\"No\\\".\n",
    "    \n",
    "    SMILES: {smiles}\n",
    "    FG-SMILES: {fg_smiles}\n",
    "    \"\"\"\n",
    "    \n",
    "    # send prompt to OpenAI\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    \n",
    "    # answer from OpenAI\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "    \n",
    "    # results dictionary\n",
    "    results[image] = answer\n",
    "\n",
    "# show results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_gemini_experimental_1206 = pd.DataFrame(results.items(), columns=[\"Image\", \"Result\"])\n",
    "\n",
    "# combine the results with the original dataframe\n",
    "df_gemini_experimental_1206 = pd.merge(df_gemini_experimental_1206, df_results_gemini_experimental_1206, on=\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a csv file\n",
    "df_gemini.to_csv(\"Metriken_gemini_experimental_1206__smiles_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selt all rows where the result is not \"Yes\" and set the result to \"No\"\n",
    "df_gemini_experimental_1206.loc[df_gemini_experimental_1206[\"Result\"] != \"Yes\", \"Result\"] = \"No\"\n",
    "\n",
    "# count the results for Yes and No\n",
    "df_gemini_experimental_1206[\"Result\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smiles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
